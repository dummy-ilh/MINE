import torch
import pandas as pd
from transformers import DistilBertTokenizer, DistilBertForSequenceClassification
from sklearn.metrics import recall_score
from sklearn.model_selection import train_test_split

# Assuming you have your data in X_train, y_train, X_val, y_val, X_test, y_test

# Create a DataFrame to store hyperparameter tuning results
columns = ['learning_rate', 'epochs', 'test_recall', 'val_recall']
tuning_results = pd.DataFrame(columns=columns)

# Function to train and evaluate the model
def train_and_evaluate(learning_rate, epochs):
    # Load pre-trained DistilBERT model and tokenizer
    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')

    # Tokenize and encode the training data
    train_inputs = tokenizer(X_train, padding=True, truncation=True, return_tensors="pt", max_length=512)
    train_labels = torch.tensor(y_train)

    # Tokenize and encode the validation data
    val_inputs = tokenizer(X_val, padding=True, truncation=True, return_tensors="pt", max_length=512)
    val_labels = torch.tensor(y_val)

    # Tokenize and encode the test data
    test_inputs = tokenizer(X_test, padding=True, truncation=True, return_tensors="pt", max_length=512)
    test_labels = torch.tensor(y_test)

    # Set up optimizer and loss function
    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)
    criterion = torch.nn.CrossEntropyLoss()

    # Training loop
    for epoch in range(epochs):
        # Forward pass
        outputs = model(**train_inputs)
        logits = outputs.logits
        loss = criterion(logits, train_labels)

        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    # Evaluation on validation set
    with torch.no_grad():
        val_outputs = model(**val_inputs)
        val_logits = val_outputs.logits
        val_preds = torch.argmax(val_logits, dim=1).numpy()
        val_recall = recall_score(y_val, val_preds, average='macro')

        # Evaluation on test set
        test_outputs = model(**test_inputs)
        test_logits = test_outputs.logits
        test_preds = torch.argmax(test_logits, dim=1).numpy()
        test_recall = recall_score(y_test, test_preds, average='macro')

    return test_recall, val_recall

# Hyperparameter tuning loop
learning_rates = [0.001, 0.01, 0.1]
epochs_list = [3, 5, 7]

for learning_rate in learning_rates:
    for epochs in epochs_list:
        test_recall, val_recall = train_and_evaluate(learning_rate, epochs)
        tuning_results = tuning_results.append({
            'learning_rate': learning_rate,
            'epochs': epochs,
            'test_recall': test_recall,
            'val_recall': val_recall
        }, ignore_index=True)

# Save the results to a CSV file
tuning_results.to_csv('hyperparameter_tuning_results.csv', index=False)
