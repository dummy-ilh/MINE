import torch
import pandas as pd
from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments
from sklearn.metrics import recall_score
from sklearn.model_selection import train_test_split

# Assuming you have your data in X_train, y_train, X_val, y_val, X_test, y_test

# Tokenize and encode the data
tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
train_encodings = tokenizer(X_train, padding=True, truncation=True, return_tensors="pt", max_length=512)
val_encodings = tokenizer(X_val, padding=True, truncation=True, return_tensors="pt", max_length=512)
test_encodings = tokenizer(X_test, padding=True, truncation=True, return_tensors="pt", max_length=512)

# Convert labels to tensors
train_labels = torch.tensor(y_train)
val_labels = torch.tensor(y_val)
test_labels = torch.tensor(y_test)

# Load pre-trained DistilBERT model
model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')

# Set up Trainer arguments
hyperparameter_grid = {
    'learning_rate': [0.001, 0.01, 0.1],
    'num_train_epochs': [3, 5, 7],
}

columns = ['learning_rate', 'num_train_epochs', 'test_recall', 'val_recall']
tuning_results = pd.DataFrame(columns=columns)

for lr in hyperparameter_grid['learning_rate']:
    for epochs in hyperparameter_grid['num_train_epochs']:
        # Define Trainer arguments
        training_args = TrainingArguments(
            output_dir=f"./distilbert-tuning/lr_{lr}_epochs_{epochs}",
            per_device_train_batch_size=8,
            per_device_eval_batch_size=8,
            learning_rate=lr,
            num_train_epochs=epochs,
            logging_dir="./logs",
        )

        # Create Trainer
        trainer = Trainer(
            model=model,
            args=training_args,
            compute_metrics=lambda p: {"recall": recall_score(p.label_ids, torch.argmax(torch.from_numpy(p.predictions), dim=1).numpy(), average='macro')},
            train_dataset=torch.utils.data.TensorDataset(train_encodings['input_ids'], train_labels),
            eval_dataset=torch.utils.data.TensorDataset(val_encodings['input_ids'], val_labels),
        )

        # Train the model
        trainer.train()

        # Evaluate on validation set
        results = trainer.evaluate(eval_dataset=torch.utils.data.TensorDataset(val_encodings['input_ids'], val_labels))
        val_recall = results['eval_recall']

        # Evaluate on test set
        test_results = trainer.predict(test_dataset=torch.utils.data.TensorDataset(test_encodings['input_ids']))
        test_recall = recall_score(y_test, torch.argmax(torch.from_numpy(test_results.predictions), dim=1).numpy(), average='macro')

        # Append results to DataFrame
        tuning_results = tuning_results.append({
            'learning_rate': lr,
            'num_train_epochs': epochs,
            'test_recall': test_recall,
            'val_recall': val_recall
        }, ignore_index=True)

# Save the results to a CSV file
tuning_results.to_csv('hyperparameter_tuning_results.csv', index=False)
