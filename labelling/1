import streamlit as st
import pandas as pd
import json
from azure_openai import AzureChatOpenAI  # Assuming you have an instance ready

# Initialize LLM
llm = AzureChatOpenAI()  

# File to store labeled data and prompt versions
LABELED_DATA_FILE = "labeled_data.json"
PROMPT_HISTORY_FILE = "prompt_versions.json"

# Load labeled data
def load_labeled_data():
    try:
        with open(LABELED_DATA_FILE, "r") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

# Save labeled data
def save_labeled_data(data):
    with open(LABELED_DATA_FILE, "w") as f:
        json.dump(data, f, indent=4)

# Load prompt history
def load_prompt_versions():
    try:
        with open(PROMPT_HISTORY_FILE, "r") as f:
            return json.load(f)
    except FileNotFoundError:
        return {"versions": []}

# Save prompt version
def save_prompt_version(prompt):
    prompt_data = load_prompt_versions()
    prompt_data["versions"].append(prompt)
    with open(PROMPT_HISTORY_FILE, "w") as f:
        json.dump(prompt_data, f, indent=4)

# Get current prompt
def get_current_prompt():
    prompt_data = load_prompt_versions()
    return prompt_data["versions"][-1] if prompt_data["versions"] else "Default prompt"

# Function to check label correctness (substring match)
def is_label_correct(predicted, user_label):
    return predicted in user_label or user_label in predicted

# Function to update prompt using LLM
def update_prompt_with_llm(incorrect_labels):
    system_message = "Improve this prompt based on incorrect labels."
    user_message = f"Here are 5 incorrect labels: {incorrect_labels}. Suggest a refined prompt."

    new_prompt = llm.invoke(system_message, user_message)
    return new_prompt

# Streamlit UI
st.sidebar.title("Navigation")
page = st.sidebar.radio("Go to", ["Data Page", "Labeling Page", "Prompt Management"])

if page == "Data Page":
    st.title("Data Page")
    uploaded_file = st.file_uploader("Upload CSV", type=["csv"])

    if uploaded_file:
        df = pd.read_csv(uploaded_file)
        st.session_state["df"] = df
        st.write(df.head())

    labeled_data = load_labeled_data()
    st.write("Current Labeled Data:", labeled_data)

elif page == "Labeling Page":
    st.title("Labeling Page")

    df = st.session_state.get("df")
    if df is None:
        st.warning("Upload a CSV file in the Data Page first.")
    else:
        record_numbers = list(range(len(df)))
        selected_record = st.selectbox("Select Record", record_numbers)

        text = df.iloc[selected_record]["text"]
        st.write(f"Text: {text}")

        # Get LLM-generated label
        llm_label = llm.invoke(get_current_prompt(), text)
        st.write(f"LLM Label: {llm_label}")

        # User input
        user_label = st.text_input("Correct Label", value=llm_label)

        if st.button("Save Label"):
            labeled_data = load_labeled_data()
            labeled_data[selected_record] = {"text": text, "llm_label": llm_label, "user_label": user_label}
            save_labeled_data(labeled_data)
            st.success("Label saved!")

            # Check correctness
            incorrect_labels = st.session_state.get("incorrect_labels", [])
            if not is_label_correct(llm_label, user_label):
                incorrect_labels.append({"text": text, "llm_label": llm_label, "user_label": user_label})
                st.session_state["incorrect_labels"] = incorrect_labels

            # If 5 incorrect, update prompt
            if len(incorrect_labels) >= 5:
                new_prompt = update_prompt_with_llm(incorrect_labels)
                save_prompt_version(new_prompt)
                st.success("Prompt updated!")
                st.session_state["incorrect_labels"] = []

elif page == "Prompt Management":
    st.title("Prompt Management")

    current_prompt = get_current_prompt()
    st.write(f"Current Prompt: {current_prompt}")

    if st.button("Revert to Previous Prompt"):
        prompt_data = load_prompt_versions()
        if len(prompt_data["versions"]) > 1:
            new_prompt = prompt_data["versions"][-2]  # Revert to previous
            save_prompt_version(new_prompt)
            st.success("Prompt reverted!")
        else:
            st.warning("No previous version available.")
