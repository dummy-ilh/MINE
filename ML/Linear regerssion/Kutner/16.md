

## Chapter 16: Single-Factor Studies

### 16.1 Single-Factor Experimental and Observational Studies (Page 677)

This section bridges the concepts of study design from Chapter 15 with the analytical techniques introduced in this chapter. It emphasizes that the methods discussed here can be applied to data arising from both single-factor experimental designs (where the factor is manipulated and randomized) and single-factor observational studies (where the factor is simply observed).

* **Single-Factor Study:** A study involving one categorical independent variable (the "factor") that has two or more levels (groups or categories), and one continuous dependent variable. The goal is to compare the mean of the dependent variable across the different levels of the factor.

* **Relation between Regression and Analysis of Variance (Page 679):**
    * **Fundamental Link:** A crucial insight is that **ANOVA is a special case of the general linear model, which can be analyzed using regression methods.** This means that any ANOVA model can be formulated as a regression model using dummy (indicator) variables for the categorical factor levels.
    * **Illustrations (Page 679):** The chapter illustrates that both regression and ANOVA can analyze the same dataset. For example, if you have three groups (A, B, C) and a continuous outcome, you could use ANOVA to test if the group means are equal. Alternatively, you could create two dummy variables (e.g., D_B = 1 if group B, 0 otherwise; D_C = 1 if group C, 0 otherwise, with group A as the reference) and run a multiple linear regression. The results (in terms of hypothesis tests about means) will be equivalent.

* **Choice between Two Types of Models (Page 680):**
    * **When to prefer ANOVA:** ANOVA notation and output are often more intuitive when the primary interest is in comparing the means of distinct groups (factor levels) and examining the overall effect of the categorical factor. It explicitly structures the variance decomposition.
    * **When to prefer Regression:** Regression is more flexible when you have a mix of categorical and continuous predictors, or when you want to specifically model the relationship between a continuous predictor and the response, or when you need to predict individual outcomes rather than just compare group means. Understanding the regression approach to ANOVA is vital for extending to more complex designs and for using general linear model software.

### 16.2 Single-Factor ANOVA Model (Page 681)

This section introduces the mathematical model that underlies single-factor ANOVA.

* **Basic Ideas (Page 681):**
    * ANOVA aims to partition the total variability in the response variable into different sources: variability *between* the factor levels (treatment effect) and variability *within* the factor levels (random error).
    * The core hypothesis is usually $H_0: \mu_1 = \mu_2 = \dots = \mu_r$, meaning all factor level means are equal.

* **Cell Means Model (Page 681):**
    * This is a common and intuitive formulation for the single-factor ANOVA model:
        $Y_{ij} = \mu_j + \epsilon_{ij}$
        Where:
        * $Y_{ij}$ is the $i$-th observation in the $j$-th factor level (or group).
        * $\mu_j$ is the true mean of the response for the $j$-th factor level.
        * $\epsilon_{ij}$ is the random error component for the $i$-th observation in the $j$-th factor level.

* **Important Features of Model (Page 682):**
    * **Errors are independent:** $\epsilon_{ij}$ are independent for all observations.
    * **Errors are normally distributed:** $\epsilon_{ij} \sim N(0, \sigma^2)$. This implies that the observations $Y_{ij}$ are also normally distributed within each group.
    * **Errors have constant variance (homoscedasticity):** $\text{Var}(\epsilon_{ij}) = \sigma^2$ for all $i$ and $j$. This means the spread of data points within each group is the same.

* **The ANOVA Model Is a Linear Model (Page 683):**
    * Despite comparing means, the cell means model $Y_{ij} = \mu_j + \epsilon_{ij}$ is linear in its parameters ($\mu_j$). This reinforces the connection to regression.

* **Interpretation of Factor Level Means (Page 684):**
    * $\mu_j$ directly represents the expected mean response for subjects/units belonging to the $j$-th factor level. The goal of ANOVA is to compare these means.

* **Distinction between ANOVA Models I and II (Page 685):**
    * **Model I (Fixed Effects Model):**
        * The factor levels being studied are specifically chosen by the experimenter (e.g., three specific drug dosages, specific fertilizer types).
        * The inferences (conclusions) apply *only* to these specific factor levels.
        * The $\mu_j$ parameters are considered fixed, non-random constants. This is the most common type of ANOVA discussed in introductory contexts.
    * **Model II (Random Effects Model):**
        * The factor levels chosen for the study are a *random sample* from a larger population of possible factor levels (e.g., 5 randomly selected batches from a manufacturing process, 10 randomly selected schools from a district).
        * The goal is to generalize inferences to the entire population of factor levels.
        * The $\mu_j$ (or the treatment effects, $\tau_j$) are considered random variables drawn from a distribution. This model is used to estimate variance components.

### 16.3 Fitting of ANOVA Model (Page 685)

This section explains how the parameters of the ANOVA model are estimated.

* **Notation (Page 686):**
    * $n_j$: Number of observations in the $j$-th factor level.
    * $r$: Number of factor levels.
    * $n_T = \sum n_j$: Total number of observations.
    * $\bar{Y}_j$: Sample mean of the $j$-th factor level. ($\bar{Y}_j = \frac{1}{n_j}\sum_{i=1}^{n_j} Y_{ij}$)
    * $\bar{\bar{Y}}$: Overall sample mean. ($\bar{\bar{Y}} = \frac{1}{n_T}\sum_{j=1}^{r}\sum_{i=1}^{n_j} Y_{ij}$)

* **Least Squares and Maximum Likelihood Estimators (Page 687):**
    * For the cell means model $Y_{ij} = \mu_j + \epsilon_{ij}$, the **least squares estimators** for the true factor level means ($\mu_j$) are simply the sample means of each group: $\hat{\mu}_j = \bar{Y}_j$.
    * Assuming normally distributed errors, these least squares estimators are also the **maximum likelihood estimators (MLEs)**.

* **Residuals (Page 689):**
    * The residual for each observation is calculated as the difference between the observed value and the estimated factor level mean: $e_{ij} = Y_{ij} - \hat{\mu}_j = Y_{ij} - \bar{Y}_j$.
    * Residuals are crucial for checking the model assumptions (normality, constant variance, independence).

### 16.4 Analysis of Variance (Page 690)

This is the core computational procedure of ANOVA, breaking down the total variability.

* **Partitioning of SSTO (Page 690):**
    * The fundamental idea is to decompose the total variation in the response variable into components attributable to different sources.
    * **Total Sum of Squares (SSTO):** Measures the total variability of all observations around the overall mean.
        $SSTO = \sum_{j=1}^r \sum_{i=1}^{n_j} (Y_{ij} - \bar{\bar{Y}})^2$
    * **Treatment Sum of Squares (SSTR):** Measures the variability *between* the factor level means (i.e., how much the group means differ from the overall mean). This represents the variation explained by the factor.
        $SSTR = \sum_{j=1}^r n_j (\bar{Y}_j - \bar{\bar{Y}})^2$
    * **Error Sum of Squares (SSE):** Measures the variability *within* each factor level (i.e., the variability of observations around their respective group means). This represents the unexplained variation or random error.
        $SSE = \sum_{j=1}^r \sum_{i=1}^{n_j} (Y_{ij} - \bar{Y}_j)^2$
    * **Fundamental Identity:** $SSTO = SSTR + SSE$

* **Breakdown of Degrees of Freedom (Page 693):**
    * The degrees of freedom (df) also partition:
        * $df_{TOTAL} = n_T - 1$
        * $df_{TRT} = r - 1$ (where $r$ is the number of factor levels)
        * $df_{ERROR} = n_T - r$
    * **Identity:** $df_{TOTAL} = df_{TRT} + df_{ERROR}$

* **Mean Squares (Page 693):**
    * Mean Squares are obtained by dividing Sum of Squares by their corresponding degrees of freedom. They represent estimates of variance.
    * **Treatment Mean Square (MSTR):** $MSTR = SSTR / (r - 1)$
    * **Error Mean Square (MSE):** $MSE = SSE / (n_T - r)$. This is an unbiased estimator of the error variance $\sigma^2$ under the model assumptions.

* **Analysis of Variance Table (Page 694):**
    * A standard table format to summarize the ANOVA results:

| Source of Variation | Degrees of Freedom (DF) | Sum of Squares (SS) | Mean Squares (MS) | F Statistic | P-value |
| :------------------ | :---------------------- | :------------------ | :---------------- | :---------- | :------ |
| Factor (Treatments) | $r-1$                   | SSTR                | MSTR              | $F^*=MSTR/MSE$ | P($F \ge F^*$) |
| Error               | $n_T-r$                 | SSE                 | MSE               |             |         |
| Total               | $n_T-1$                 | SSTO                |                   |             |         |

* **Expected Mean Squares (Page 694):**
    * **$E\{MSE\} = \sigma^2$:** Regardless of whether $H_0$ is true or false, MSE is an unbiased estimate of the error variance.
    * **$E\{MSTR\} = \sigma^2 + \frac{\sum n_j (\mu_j - \bar{\mu})^2}{r-1}$ (for fixed effects model):**
        * If $H_0$ is true (all $\mu_j$ are equal), then $\sum n_j (\mu_j - \bar{\mu})^2 = 0$, so $E\{MSTR\} = \sigma^2$.
        * If $H_0$ is false, then $E\{MSTR\} > \sigma^2$.
    * Understanding expected mean squares is critical for justifying the F-test and for distinguishing between fixed and random effects models.

### 16.5 F Test for Equality of Factor Level Means (Page 698)

This is the primary hypothesis test in single-factor ANOVA.

* **Test Statistic (Page 698):**
    * $F^* = MSTR / MSE$
    * **Logic:** If the factor level means are truly equal ($H_0$ is true), then MSTR and MSE should both be estimating the same population error variance $\sigma^2$, so their ratio ($F^*$) should be close to 1. If the factor level means are different ($H_a$ is true), then MSTR will tend to be larger than MSE (as it contains variability due to treatment effects in addition to error), making $F^*$ greater than 1.

* **Distribution of F (Page 699):**
    * If $H_0$ is true and model assumptions hold, $F^*$ follows an **F-distribution** with $df_1 = (r-1)$ (numerator degrees of freedom) and $df_2 = (n_T - r)$ (denominator degrees of freedom).

* **Construction of Decision Rule (Page 699):**
    * Compare $F^*$ to a critical value $F_{\alpha}(r-1, n_T-r)$ from the F-distribution table (or use the P-value).
    * **Decision Rule:**
        * If $F^* \ge F_{\alpha}$, reject $H_0$. (Or if P-value $\le \alpha$, reject $H_0$).
        * Conclusion: There is sufficient evidence to conclude that at least one factor level mean is different from the others.
    * **Important:** The F-test is an **omnibus test**. It tells you *if* there's a difference, but not *which* specific means differ. Post-hoc tests (covered in later chapters) are needed for pairwise comparisons.

### 16.6 Alternative Formulation of Model (Page 701)

This section introduces a different but equivalent way to write the ANOVA model, often called the "effects model."

* **Factor Effects Model (Page 701):**
    * $Y_{ij} = \mu + \tau_j + \epsilon_{ij}$
    * Where:
        * $\mu$ is the overall mean (a common baseline for all observations).
        * $\tau_j$ is the **treatment effect** (or factor effect) for the $j$-th factor level. It represents the deviation of the $j$-th factor level mean from the overall mean: $\tau_j = \mu_j - \mu$.
        * $\epsilon_{ij}$ is the random error.

* **Definition of $\tau_j$ (Page 702):**
    * The $\tau_j$ values represent the specific effect of each treatment beyond the overall mean.
    * To make the model uniquely estimable (identifiable), a constraint is typically imposed on the $\tau_j$ values. Common constraints include:
        * $\sum_{j=1}^r \tau_j = 0$ (unweighted means constraint)
        * $\sum_{j=1}^r n_j \tau_j = 0$ (weighted means constraint, less common for inference)
        * $\tau_r = 0$ (sets the last treatment level as a reference, similar to dummy variables in regression).

* **Test for Equality of Factor Level Means (Page 704):**
    * The hypothesis $H_0: \mu_1 = \mu_2 = \dots = \mu_r$ is equivalent to testing $H_0: \tau_1 = \tau_2 = \dots = \tau_r = 0$. The F-test described in 16.5 still applies directly to this formulation.

### 16.7 Regression Approach to Single-Factor Analysis of Variance (Page 704)

This section explicitly demonstrates how ANOVA is a regression model, using dummy variables.

* **Factor Effects Model with Unweighted Mean (Page 705):**
    * Using dummy variables (indicator variables) for $r-1$ factor levels, with one level serving as the reference category.
    * *Example:* For 3 factor levels (A, B, C), if A is the reference:
        $Y_i = \beta_0 + \beta_1 X_{iB} + \beta_2 X_{iC} + \epsilon_i$
        Where $X_{iB}=1$ if observation $i$ is in group B, 0 otherwise; $X_{iC}=1$ if in group C, 0 otherwise.
        * $\beta_0$ estimates $\mu_A$.
        * $\beta_1$ estimates $\mu_B - \mu_A$.
        * $\beta_2$ estimates $\mu_C - \mu_A$.
    * Testing $H_0: \mu_A = \mu_B = \mu_C$ is equivalent to testing $H_0: \beta_1 = \beta_2 = 0$ using an F-test (or a likelihood ratio test for GLMs). The F-statistic from this regression model will be identical to the F-statistic from the ANOVA table.

* **Factor Effects Model with Weighted Mean (Page 709):**
    * This typically uses different coding schemes for dummy variables (e.g., sum-to-zero coding) that allow $\beta_0$ to represent the overall mean and $\beta_j$ to represent deviations from that overall mean. This might be used if the concept of an unweighted grand mean is important.

* **Cell Means Model (Page 710):**
    * This formulation uses $r$ dummy variables, one for each factor level, but *without an intercept term*.
    * *Example:* For 3 factor levels (A, B, C):
        $Y_i = \beta_A X_{iA} + \beta_B X_{iB} + \beta_C X_{iC} + \epsilon_i$
        Where $X_{iA}=1$ if observation $i$ is in group A, 0 otherwise (and similarly for B and C).
        * $\beta_A$ estimates $\mu_A$.
        * $\beta_B$ estimates $\mu_B$.
        * $\beta_C$ estimates $\mu_C$.
    * This directly estimates the cell means, making it very straightforward to interpret. Testing equality of means still requires a joint test on these coefficients.

### 16.8 Randomization Tests (Page 712)

* **Concept:** Randomization tests (also known as permutation tests) are non-parametric alternatives to the traditional F-test.
* **How it works:** Instead of relying on assumptions of normality and constant variance, it directly uses the principle of random assignment.
    1.  Calculate the $F^*$ statistic for the observed data.
    2.  Randomly re-shuffle (permute) the observed response values among the treatment groups many times (e.g., 1,000 or 10,000 times), *as if the null hypothesis of no treatment effect were true*.
    3.  For each permutation, calculate a new $F^*$ statistic.
    4.  The p-value is the proportion of these permuted $F^*$ statistics that are as extreme as (or more extreme than) the observed $F^*$.
* **Advantage:** Does not require assumptions of normality or equal variance.
* **Disadvantage:** Computationally intensive (though modern computers handle it easily); results are slightly different each time due to random permutations.

### 16.9 Planning of Sample Sizes with Power Approach (Page 716)

This section addresses how to determine the necessary sample size *before* conducting a study.

* **Power of F Test (Page 716):**
    * **Power:** The probability of correctly rejecting a false null hypothesis ($1 - \beta$, where $\beta$ is the probability of a Type II error). It's the probability of detecting a true difference when one exists.
    * **Factors influencing Power:**
        1.  **Effect Size:** The magnitude of the true differences between the population means (larger differences are easier to detect).
        2.  **Alpha ($\alpha$):** The significance level (lower $\alpha$ means lower power).
        3.  **Error Variance ($\sigma^2$):** Smaller variance (more precise measurements, less noise) means higher power.
        4.  **Sample Size ($n_T$):** Larger sample size means higher power.
        5.  **Number of factor levels ($r$):** More groups can sometimes reduce power for a fixed total N.

* **Use of Table B.12 for Single-Factor Studies (Page 718):**
    * This refers to power tables/charts (often found in appendices of textbooks) that help determine sample size or power based on:
        * Desired $\alpha$ level.
        * Desired power.
        * Number of factor levels ($r$).
        * A measure of **effect size**, often standardized by the error standard deviation (e.g., Cohen's $f$). This requires researchers to specify what "meaningful difference" between means they want to be able to detect.

* **Some Further Observations on Use of Table B.12 (Page 720):**
    * Emphasizes the iterative nature of power calculation, often involving estimating effect size from prior research or pilot studies.
    * Discusses the practical trade-offs between desired power, detectable effect size, and available resources for sample size.

### 16.10 Planning of Sample Sizes to Find "Best" Treatment (Page 721)

* This is a specialized power calculation problem. Instead of just testing if *any* means differ, this focuses on ensuring sufficient sample size to identify the treatment with the highest (or lowest) mean with a certain level of confidence or probability, especially if there are multiple treatments. It often involves more complex power calculations than the general F-test power.
