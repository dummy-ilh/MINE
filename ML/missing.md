Great choice â€” **Missing Data** is one of the most overlooked but **fundamental topics in ML and statistics**, and itâ€™s a hot topic in interviews at places like **Google, Amazon, and research teams**.

---

## ğŸ“˜ MASTER NOTES: **Missing Data in Machine Learning**

---

### ğŸ”¹ 1. DEFINITION

**Missing data** occurs when no value is stored for a feature in a dataset for a given observation.

---

### ğŸ”¹ 2. TYPES OF MISSINGNESS (very important!)

| Type                                    | Definition                                                          | Example                                      | Assumption                         |
| --------------------------------------- | ------------------------------------------------------------------- | -------------------------------------------- | ---------------------------------- |
| **MCAR** (Missing Completely at Random) | Missingness has **no relation** to any data, observed or unobserved | A sensor randomly fails                      | Data is unbiased, but info is lost |
| **MAR** (Missing at Random)             | Missingness depends **only on observed data**                       | Males skip weight entry, but gender is known | Can correct with modeling          |
| **MNAR** (Missing Not at Random)        | Missingness depends on **unobserved values**                        | People with high income donâ€™t report income  | Cannot be ignored, must be modeled |

ğŸ§  **Interview Tip**: Understanding this distinction is critical to justify your imputation method.

---

### ğŸ”¹ 3. NOTATION AND FORMULATION

Let:

* $Y = \text{data matrix}$
* $Y_{obs} = \text{observed part}$
* $Y_{mis} = \text{missing part}$
* $R = \text{missingness indicator (1 if observed, 0 if missing)}$

**Goal**: Model $P(Y_{mis} | Y_{obs}, R)$

Under MAR:

$$
P(R | Y_{obs}, Y_{mis}) = P(R | Y_{obs})
$$

---

### ğŸ”¹ 4. IMPUTATION TECHNIQUES

| Method                             | Description                               | Pros                    | Cons                      |
| ---------------------------------- | ----------------------------------------- | ----------------------- | ------------------------- |
| **Mean/Median**                    | Fill missing with column mean or median   | Fast, easy              | Underestimates variance   |
| **Mode (categorical)**             | Use most frequent value                   | Simple                  | Ignores dependencies      |
| **KNN Imputation**                 | Use k-nearest rows to predict missing     | Accounts for similarity | Slow on large data        |
| **Multivariate Imputation (MICE)** | Models each feature as function of others | Captures correlation    | Slower, complex           |
| **Regression Imputation**          | Predict missing values using regression   | Better than mean        | Still biased              |
| **Deep Learning**                  | Autoencoders or GANs for imputation       | High-quality            | Needs more data, training |
| **Drop rows/columns**              | Remove incomplete rows or columns         | Safe if few missing     | Loss of data/information  |

ğŸ§ª Code example (mean imputation with pandas):

```python
import pandas as pd
df = pd.read_csv("data.csv")
df['feature'] = df['feature'].fillna(df['feature'].mean())
```

---

### ğŸ”¹ 5. VISUALIZATION TOOLS

Use these tools to explore missingness:

```python
import seaborn as sns
import missingno as msno

msno.matrix(df)
msno.heatmap(df)
```

---

### ğŸ”¹ 6. ADVANCED STRATEGIES

#### ğŸ”¸ Indicator Variables:

Add a binary column indicating whether the original value was missing.

```python
df['feature_missing'] = df['feature'].isnull().astype(int)
```

#### ğŸ”¸ Multiple Imputation:

Generates multiple versions of the dataset with imputed values â†’ models trained on all â†’ results pooled.

---

### ğŸ”¹ 7. COMMON INTERVIEW QUESTIONS

| Question                                             | Company | Tip                                            |
| ---------------------------------------------------- | ------- | ---------------------------------------------- |
| How would you handle missing data in a pipeline?     | Google  | Discuss types, imputation, and modeling        |
| Can you explain the difference between MAR and MNAR? | Amazon  | Give a real-life example                       |
| How does missing data affect bias and variance?      | Meta    | Show you understand trade-offs                 |
| Would you drop rows or impute?                       | Twitter | Depends on % missing and MCAR/MAR              |
| How would you impute time series missing values?     | Apple   | Talk about forward fill, interpolation, models |

---

### ğŸ”¹ 8. LINKS TO VISUALS & RESOURCES

* ğŸ”— [Missing Data Visualization Tool: missingno](https://github.com/ResidentMario/missingno)
* ğŸ“ˆ [Kaggle: Titanic Missing Value Heatmap](https://www.kaggle.com/code/pmarcelino/comprehensive-data-exploration-with-python)
* ğŸ“˜ [Little & Rubinâ€™s Statistical Analysis with Missing Data (book)](https://onlinelibrary.wiley.com/doi/book/10.1002/9781119013563)

---

## âœ… TL;DR CHEAT SHEET

```
1. MCAR â†’ Random missing â†’ Drop is OK
2. MAR â†’ Depends on observed â†’ Imputation works
3. MNAR â†’ Depends on hidden â†’ Must model the mechanism

Basic: mean, median, mode
Smart: KNN, regression, MICE
Advanced: Deep Learning, Autoencoders
Always check % missing + correlation
```

---

Would you like:

* A **LaTeX-formatted PDF version** of this?
* The **code templates** for MICE, KNN, Autoencoder?
* To go to the **next concept** (suggested: Regularization, Bias-Variance, or Feature Selection)?
Perfect â€” let's now **deep dive into the most advanced answers** for each of the questions you mentioned, giving you mastery-level clarity, mathematical depth, and research-ready formulations.

---

## âœ… STATISTICAL & THEORETICAL QUESTIONS â€” IN-DEPTH ANSWERS

---

### â“ **1. What assumptions must hold for listwise deletion to be unbiased?**

**Listwise deletion** (also called **complete case analysis**) removes any row with missing values.
It yields **unbiased parameter estimates only if data is MCAR**.

#### âœ… Assumptions:

* The probability of a missing value is **independent of both observed and unobserved data**.

$$
P(R = 1 | Y_{obs}, Y_{mis}) = P(R = 1)
$$

* This ensures that the missing data is **a random subsample**, and the remaining data is still representative.

#### ğŸš« Under MAR or MNAR:

* **MAR**: missingness depends on observed variables â†’ deletion creates bias.
* **MNAR**: missingness depends on unobserved variables â†’ serious bias and loss of information.

---

### â“ **2. Why does mean imputation underestimate variance? Derive the impact.**

**Mean imputation** replaces missing values with the variableâ€™s mean:

$$
x_i = \begin{cases}
x_i & \text{if observed} \\
\bar{x} & \text{if missing}
\end{cases}
$$

#### ğŸ§  Intuition:

* You're shrinking missing values toward the center.
* No variance is introduced by these imputed points, so the variance is **biased downward**.

#### ğŸ“‰ Effect on variance:

Let $\sigma^2$ be the true variance. Suppose $m$ out of $n$ values are missing.

After mean imputation:

$$
\text{Var}_{\text{mean imp}} = \frac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x})^2 \leq \text{True Var}
$$

It **ignores the uncertainty** in the imputed values, leading to:

* **Underestimated variance**
* **Downward bias in standard errors**
* **Overconfident models**

---

### â“ **3. What is the likelihood function under MAR vs MNAR?**

#### ğŸ“Œ Let:

* $Y = (Y_{obs}, Y_{mis})$
* $R$ = missingness indicator matrix

---

#### Under **MAR**:

Missingness depends only on observed data:

$$
P(R | Y_{obs}, Y_{mis}) = P(R | Y_{obs})
$$

The **observed-data likelihood** becomes:

$$
L(\theta) = \int P(Y_{obs}, Y_{mis} | \theta) dY_{mis}
$$

and the full likelihood:

$$
P(Y_{obs}, R | \theta, \phi) = P(R | Y_{obs}; \phi) \cdot \int P(Y_{obs}, Y_{mis} | \theta) dY_{mis}
$$

ğŸ‘‰ We can **ignore the missingness mechanism** when estimating $\theta$ â€” called **ignorability**.

---

#### Under **MNAR**:

$$
P(R | Y_{obs}, Y_{mis}) \neq P(R | Y_{obs})
$$

Then:

$$
P(Y_{obs}, R | \theta, \phi) = \int P(Y_{obs}, Y_{mis} | \theta) P(R | Y_{obs}, Y_{mis}; \phi) dY_{mis}
$$

ğŸ‘‰ Must **model the missingness mechanism** â†’ requires **joint modeling** â†’ very difficult!

---

### â“ **4. How would you formally test whether data is MCAR vs MAR?**

#### âœ… 1. **Littleâ€™s MCAR Test**:

* Tests the null hypothesis: data is MCAR.
* Uses a chi-square statistic to compare means across patterns of missingness.

ğŸ§ª If p-value is small â†’ reject MCAR â†’ maybe MAR/MNAR.

Python:

```python
from statsmodels.imputation import mice
mice.MICEData(df).test_missing_pattern()
```

---

#### âœ… 2. **Logistic Regression on Missingness**:

* Create binary missingness indicators for each variable.
* Predict them using observed variables.

$$
P(R_i = 1 | X_{obs})
$$

ğŸ“Œ If prediction accuracy is **significant**, then missingness depends on observed variables â†’ **MAR**.

---

### â“ **5. What is Rubinâ€™s Classification of Missing Data? How does it relate to identifiability?**

**Rubin (1976)** introduced a taxonomy:

| Type | Missingness depends on | Implication                      |
| ---- | ---------------------- | -------------------------------- |
| MCAR | Nothing (fully random) | Complete-case is unbiased        |
| MAR  | Observed values        | Imputation or weighting can work |
| MNAR | Unobserved values      | Must model missingness mechanism |

---

#### ğŸ” **Ignorability**

If data is MAR and parameters governing missingness are **independent** of model parameters, then:

* Missingness is **ignorable**
* Likelihood can be maximized using observed data

---

## âœ… PRACTICAL ML QUESTIONS â€” IN-DEPTH ANSWERS

---

### â“ 6. **You have 25% missing in a key feature â€” what do you do?**

**Step-by-step**:

1. Profile the data: missing heatmap (`missingno`)
2. Check correlation with missingness â†’ MCAR/MAR/MNAR?
3. Does the variable impact model performance? (feature importance)
4. Choose:

   * If MCAR + small effect â†’ drop
   * If MAR â†’ impute using advanced techniques
   * If MNAR â†’ possibly model missingness mechanism

ğŸ’¡ Consider: add missing indicator column to retain signal of missingness.

---

### â“ 7. **How do tree-based models handle missing values?**

#### CART / Decision Trees:

* Use **surrogate splits**: if primary feature is missing, fallback to correlated split.

#### XGBoost:

* Assigns missing values to the **optimal direction** that minimizes loss.

#### LightGBM:

* Adds a **separate bin** for missing values.

ğŸ“Œ These models **learn from missingness** â€” unlike linear models.

---

### â“ 8. **KNN imputation: how to choose k, and deal with scale?**

* Normalize features with `StandardScaler` before applying KNN.
* Tune `k` using cross-validation (use `GridSearchCV` with pipeline).
* Watch for:

  * Curse of dimensionality
  * Imputation bias when outliers dominate

```python
from sklearn.impute import KNNImputer
from sklearn.preprocessing import StandardScaler
```

---

### â“ 9. **Imputation done on train but not test data â€” whatâ€™s the risk?**

ğŸš¨ **Data Leakage**:

* If you impute on the full dataset, you **leak target statistics** (e.g., mean) from test â†’ train
* Leads to **over-optimistic model performance**

âœ… Solution: Use `Pipeline` to learn imputation **only from training data**, and apply to test set.

---

### â“ 10. **Impute before or after train-test split? Why?**

* Always **split first**, then impute.
* Otherwise, you contaminate the validation/test set â†’ invalid evaluation.

âœ… Use:

```python
from sklearn.pipeline import Pipeline
```

---

## âœ… ADVANCED QUESTIONS â€” IN-DEPTH ANSWERS

---

### â“ 11. **Using Variational Autoencoders (VAE) for imputation**

* Input: partially observed vector $x$
* Mask missing entries
* Encode into latent $z$, decode to reconstruct missing

Loss:

$$
\mathcal{L} = \text{Reconstruction Loss (only observed)} + \text{KL}(q(z|x) \| p(z))
$$

ğŸ“Œ Advantages:

* Nonlinear structure learning
* Works well on images, text, sensor data

---

### â“ 12. **EM Algorithm for Gaussian Data with Missingness**

#### Goal:

Estimate mean $\mu$, covariance $\Sigma$ of Gaussian data $X$ with missing entries.

---

#### E-step:

Compute:

$$
\mathbb{E}[X_{mis} | X_{obs}, \mu^{(t)}, \Sigma^{(t)}]
$$

Use conditional expectation of multivariate Gaussian.

---

#### M-step:

Update $\mu$, $\Sigma$ using the completed data:

$$
\mu^{(t+1)} = \frac{1}{n} \sum_i \hat{x}_i
$$

$$
\Sigma^{(t+1)} = \frac{1}{n} \sum_i (\hat{x}_i - \mu)(\hat{x}_i - \mu)^T
$$

---

### â“ 13. **How does MICE work and why is it better than single imputation?**

* Iteratively fills missing values **column by column** using regression models.
* Imputes each variable $X_j$ as a function of all others:

$$
X_j = f_j(X_{-j})
$$

* Cycles through each variable multiple times.
* Adds **sampling noise** â†’ allows **multiple datasets** to reflect uncertainty.

ğŸ“Œ Better than:

* Mean (underestimates variance)
* Regression (biased)

---

### â“ 14. **Income is MNAR â€” what do you do?**

* You **cannot ignore** or blindly impute.
* Consider:

  * **Heckman correction model**
  * **Bayesian modeling of missingness**
  * **Pattern mixture models**
  * **Sensitivity analysis** to assess robustness of assumptions

---

### â“ 15. **Predictive Mean Matching (PMM) vs Regression Imputation**

| Aspect         | PMM                                       | Regression                       |
| -------------- | ----------------------------------------- | -------------------------------- |
| Mechanism      | Match predicted value to closest observed | Plug predicted value             |
| Distribution   | Preserves data distribution               | Smooths, underestimates variance |
| Outliers       | Safer                                     | Sensitive                        |
| Implementation | Slower                                    | Easier                           |

PMM is a hybrid â†’ combines **predictive accuracy with realism**.

---

## âš¡ NEXT STEPS

Would you like me to now:

* Convert this into a **LaTeX-formatted PDF** or **Notion-ready document**?
* Generate **Python notebooks** for: MICE, EM, Autoencoder Imputation?
* Go to the **next topic**: Suggestions:

  1. âœ… Regularization (L1/L2, ridge, lasso)
  2. âœ… Bias-Variance Tradeoff
  3. âœ… Cross-Validation
  4. âœ… SVM & Kernels
  5. âœ… Decision Trees

Just say: **"Next: \[your topic]"** or **"Make a PDF"** or **"Give me MICE code"**.


Absolutely â€” hereâ€™s a list of **critical, high-leverage questions** that deeply test your understanding of **missing values**. These go beyond textbook answers and are designed to be **used in top-tier interviews or oral exams** to probe:

* Your **statistical grounding**
* Real-world **ML engineering judgment**
* Edge-case handling and **modeling philosophy**

---

## ğŸš¨ CRITICAL MISSING VALUE QUESTIONS TO TEST DEEP UNDERSTANDING

---

### ğŸ” THEORY & STATISTICS

1. **Whatâ€™s the consequence of using mean imputation on the distribution and correlation structure of your data?**
   â†’ *(Think: loss of variance, distortion of relationships, underestimation of standard error, and impact on regression coefficients.)*

---

2. **How would you design an experiment to determine whether your data is MAR or MNAR?**
   â†’ *(Trick: You can't empirically distinguish MAR from MNAR using the dataset alone. Must use domain knowledge or perform sensitivity analysis.)*

---

3. **You have 15% missing values in a feature. Should you impute, drop, or model it directly? What governs your choice?**
   â†’ *(Depends on the missingness mechanism, predictive power, correlation with missingness, model type, business context.)*

---

4. **Why is multiple imputation preferred over single imputation? What statistical problem does it solve?**
   â†’ *(Uncertainty quantification â€” multiple imputed datasets reflect variability of the imputation model â†’ valid confidence intervals.)*

---

5. **If the missingness depends on the unobserved value itself (MNAR), what assumptions must be made for unbiased inference?**
   â†’ *(You must model the missingness mechanism jointly with the data â†’ ex. selection models like Heckman correction.)*

---

### ğŸ”§ MACHINE LEARNING PRACTICE

6. **You build a model with mean imputation. It performs worse on live production data. Why might that be?**
   â†’ *(Train-test mismatch due to different missingness patterns, ignored variance, misaligned marginal distributions.)*

---

7. **Why should you impute after the train-test split and not before?**
   â†’ *(To prevent data leakage â€” test set statistics should not influence training data imputation.)*

---

8. **How do models like XGBoost or LightGBM leverage missing values as signal rather than a problem?**
   â†’ *(They learn split directions for missing values or assign them to optimal bins â€” effectively using â€œmissingness as a feature.â€)*

---

9. **Is it ever useful to retain a missingness indicator variable even after imputation? Why or why not?**
   â†’ *(Yes â€” especially in MAR or MNAR. The pattern of missingness can carry predictive signal.)*

---

10. **Suppose your dataset has MNAR values, but your model performs well in validation. Should you care?**
    â†’ *(Yes â€” because the model may break in real-world scenarios where missingness pattern shifts. Your validation set may not reflect deployment conditions.)*

---

### ğŸ§  CONCEPTUAL JUDGMENT

11. **Is it better to drop rows or impute when <5% data is missing? Why or why not?**
    â†’ *(Depends: if MCAR, drop might be okay; but imputation may retain valuable rows when data is limited. Also depends on sample size and importance of the feature.)*

---

12. **Youâ€™re given a clinical dataset where lab values are missing only for patients in better health. What does this imply, and what should you do?**
    â†’ *(This is MNAR â€” missingness carries information. Ignoring it or using naive imputation will bias estimates. Consider joint modeling or missingness indicators.)*

---

13. **How would you explain the difference between MCAR and MAR to a non-technical stakeholder using a business example?**
    â†’ *(Example: MCAR = survey lost in mail; MAR = older people more likely to skip tech questions â€” but you know age.)*

---

14. **If your imputation method is too aggressive, whatâ€™s the consequence on model performance and generalization?**
    â†’ *(Overconfidence, underestimated uncertainty, optimistic validation metrics, poor robustness to distributional shift.)*

---

15. **How does missing data impact statistical inference differently than predictive modeling?**
    â†’ *(Inference requires valid variance estimation â†’ missing data affects standard errors and confidence intervals. Prediction can tolerate certain biases as long as accuracy holds.)*

---

## ğŸ§ª Want to Test Yourself?

I can turn these into:

* âœ… An **interactive quiz**
* ğŸ“„ A printable **oral exam prep PDF**
* ğŸ“š A **case study scenario** (e.g., hospital dataset with MNAR lab results)

Would you like to:

* Drill on **code-based missing data problems**?
* Practice a **case-style modeling exercise**?
* Move to **another concept** (Regularization, Bias-Variance, etc.)?
Excellent â€” letâ€™s tackle each point in-depth with **examples**, **intuition**, and **interview-ready answers**, so you deeply understand **missing data theory + application**.

---

## âœ… 1) **Examples of MCAR, MAR, and MNAR**

### ğŸ”¹ **MCAR â€“ Missing Completely at Random**

**Definition:** The missingness is unrelated to any variable â€” observed or unobserved.

| Example                                         | Explanation                                |
| ----------------------------------------------- | ------------------------------------------ |
| Survey sheets lost in transit                   | Whether data is missing is purely random   |
| A sensor fails occasionally due to power outage | Not related to value or any other variable |
| Random database corruption                      | External failure, not data-dependent       |

âœ… **Analysis remains unbiased**
âŒ **Less common in real world**

---

### ğŸ”¹ **MAR â€“ Missing At Random**

**Definition:** Missingness is related only to **observed variables**, not to the missing value itself.

| Example                                                     | Explanation                                  |
| ----------------------------------------------------------- | -------------------------------------------- |
| Women tend to skip income question, but gender is known     | Missingness depends on gender (observed)     |
| Younger users skip retirement planning questions            | Age is known, so missingness is explainable  |
| Diabetics skip calorie intake, and diabetes status is known | Imputation can adjust using known predictors |

âœ… Can use **regression/mice/knn** for imputation
ğŸ” **Testable via modeling**

---

### ğŸ”¹ **MNAR â€“ Missing Not At Random**

**Definition:** Missingness is related to the **value that is missing** or some **unobserved variable**.

| Example                                               | Explanation                                |
| ----------------------------------------------------- | ------------------------------------------ |
| High-income people are less likely to disclose salary | Missingness depends on true (unseen) value |
| Patients with severe disease drop out of study        | Health status not observed â†’ bias          |
| Depression survey: severely depressed skip the test   | Value itself causes the missingness        |

âŒ **Untestable from data alone**
ğŸ”¬ Requires **domain knowledge** or **modeling the missing mechanism**

---

## âœ… 2) **How Does Deletion Lead to Bias?**

Letâ€™s say your dataset has income missing **only for high earners** (MNAR).

If you use **listwise deletion**, you are removing:

* A **non-random sample** of the data
* Biased toward lower incomes
* Mean income appears lower than reality

### ğŸ” Why Itâ€™s Biased:

* Your model trains only on **observed** data
* But observed â‰  population due to **non-random missingness**

#### Example:

| Income (true) | Observed? |
| ------------- | --------- |
| â‚¹10,000       | âœ…         |
| â‚¹1,00,000     | âŒ         |
| â‚¹20,000       | âœ…         |

â†’ Mean of observed = â‚¹15,000 â†’ **severely biased**.

âœ… If data is MCAR â†’ deletion is unbiased
âŒ If MAR/MNAR â†’ deletion creates bias in estimates

---

## âœ… 3) **How to Test for Missingness Type**

### ğŸ”¹ Step-by-Step

#### 1. **Visual Tools**:

* `missingno.matrix(df)`
* `missingno.heatmap(df)`

---

#### 2. **Littleâ€™s MCAR Test**

* Tests whether missing data is MCAR
* Null hypothesis: data is MCAR

```python
from statsmodels.imputation import mice
mice_data = mice.MICEData(df)
mice_data.test_missing_pattern()
```

---

#### 3. **Logistic Regression on Missingness**

Create binary indicator of missingness and model it:

```python
df['feature_missing'] = df['feature'].isnull().astype(int)
model = LogisticRegression().fit(df[observed_cols], df['feature_missing'])
```

âœ… If prediction accuracy is high â†’ evidence of **MAR**

---

#### 4. **Domain Expertise**

* If missingness depends on the missing value â†’ **MNAR** (not testable from data alone)
* Use **sensitivity analysis**

---

## âœ… 4) **How to Handle Missing Data â€” Q\&A Style**

| Question                                             | Suggested Answer                                                      |
| ---------------------------------------------------- | --------------------------------------------------------------------- |
| What are your first steps when you see missing data? | Visualize patterns, create missing indicators, check % missing        |
| When would you drop vs impute?                       | Drop if MCAR + small %, impute if MAR, model if MNAR                  |
| Whatâ€™s the safest basic imputation?                  | Median for numeric, mode for categorical (less sensitive to outliers) |
| Best practice for imputation + modeling?             | Use pipeline with `SimpleImputer` or `KNNImputer` + model             |
| How to preserve signal of missingness?               | Add binary indicators (feature\_missing = 1 if missing)               |
| How to handle missing in time series?                | Use interpolation, forward/backward fill, or time-aware models        |

---

## âœ… 5) **How Do Tree-Based Models Handle Missing Values?**

### ğŸ” Trees Handle Missingness Natively! Thatâ€™s a huge plus.

#### ğŸ¯ CART (Decision Trees):

* Uses **surrogate splits**
* If primary split feature is missing, uses backup feature with similar split

---

#### ğŸ¯ XGBoost:

* Sends missing values to a **learned default direction** that minimizes loss

```python
xgboost.train(..., missing=np.nan)
```

---

#### ğŸ¯ LightGBM:

* Adds a **â€œmissingâ€ bin** in histogram-based splitting
* Learns which side of the split missing values should go to

---

âœ… Advantage: Trees **learn from missingness**

* If missingness correlates with target, they capture it
* No need for external imputation

---

## âœ… 6) **What Is Data Leakage? Why Is It a Problem?**

### â— Data leakage = when information from **outside the training data** is used to create the model.

### ğŸ”¥ Example of Leakage in Missing Data:

You impute missing values using the **mean of the entire dataset** (train + test) **before splitting**.

ğŸ”» This means:

* Youâ€™re using info from test set to fill train set â†’ **invalid model evaluation**

---

### ğŸ” Leakage Can Occur When:

| Scenario                         | Why Itâ€™s Leakage                                              |
| -------------------------------- | ------------------------------------------------------------- |
| Imputing before train-test split | Future info contaminates training                             |
| Scaling before split             | Same issue                                                    |
| Feature engineered using target  | "Target leakage" (e.g., using `loan_paid` to predict default) |

---

### âœ… Best Practices to Avoid Leakage:

* Always **split train/test first**
* Use **sklearn.Pipeline** to combine imputation + scaling + modeling
* Validate with **cross-validation**

```python
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier

pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('model', RandomForestClassifier())
])
```

---

## âœ… TL;DR Summary

| Topic         | Key Idea                                             |
| ------------- | ---------------------------------------------------- |
| MCAR          | Randomly missing â†’ drop is OK                        |
| MAR           | Depends on observed vars â†’ imputation safe           |
| MNAR          | Depends on unobserved/missing value â†’ needs modeling |
| Deletion Bias | Deletes biased subsample if not MCAR                 |
| Trees         | Handle missing smartly (surrogate/default)           |
| Leakage       | Info from test influences train â†’ invalid model      |

---

Would you like:

* ğŸ“˜ This turned into a **notebook or printable PDF**?
* ğŸ§ª A **code walkthrough** with real dataset missing handling?
* ğŸ” Move to next ML topic (e.g., **Regularization**, **Bias-Variance**, **Cross-Validation**)?
