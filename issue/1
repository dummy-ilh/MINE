# streamlit_langchain_app.py

import streamlit as st
import json
from langchain.prompts import PromptTemplate
from langchain.chat_models import AzureChatOpenAI
from langchain.schema import HumanMessage

# Load dictionary data from a text file
def load_dict(file_path):
    with open(file_path, 'r') as f:
        data = json.load(f)
    return data

# Initialize Azure OpenAI (replace with your Azure settings)
def load_azure_openai():
    return AzureChatOpenAI(
        deployment_name="YOUR_AZURE_DEPLOYMENT_NAME",  # Azure deployment name
        openai_api_key="YOUR_AZURE_API_KEY",           # Azure API key
        api_version="2023-03-15-preview"              # Use correct API version
    )

# Load the model and set up caching for efficiency
llm = load_azure_openai()

# Load dictionary of issues from a file
dict_file = 'issues_dict.json'  # Path to your dictionary file
issues_dict = load_dict(dict_file)

# Streamlit App
st.title("Executive Summary Generator")

# Input section: Dropdown or Text Box
st.subheader("Input Options")
option_selected = st.selectbox("Select an issue:", ["None"] + list(issues_dict.keys()))
input_text = st.text_area("Or enter your text here:")

# Validate input: either dropdown or text input should be filled, not both
if option_selected != "None" and input_text:
    st.warning("Please choose either the dropdown or enter text, but not both.")
elif option_selected == "None" and not input_text:
    st.warning("Please select an issue from the dropdown or enter text in the box.")
else:
    if st.button("Submit"):
        # If a dropdown selection is made, use that as the input, otherwise use the entered text
        if option_selected != "None":
            selected_issue = issues_dict[option_selected]
            prompt_text = f"Summarize the following issue: {selected_issue}"
            st.write(f"**Selected Issue Text:** {selected_issue}")
        else:
            prompt_text = f"Summarize the following text: {input_text}"
            st.write(f"**Input Text:** {input_text}")

        # Create a prompt template and use it to generate a summary
        prompt_template = PromptTemplate(
            input_variables=["text"],
            template="Please write an executive summary based on the following: {text}"
        )

        # Prepare the final prompt to send to the model
        final_prompt = prompt_template.format(text=prompt_text)

        # Pass the prompt to the AzureChatOpenAI model for generating a summary
        with st.spinner("Generating summary..."):
            response = llm([HumanMessage(content=final_prompt)])

        # Extract and display the summary from the response
        summary = response.content
        st.subheader("Generated Summary")
        st.write(summary)
